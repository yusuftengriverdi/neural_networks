{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from torch.utils.data import DataLoader , TensorDataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"model-{time.asctime()}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 75\n",
    "EPOCHS = 30\n",
    "PT = \"model/model2.pt\" #path to existing model\n",
    "IMG_SIZE = 50\n",
    "VAL_PCT = 0.1\n",
    "LR = 0.001\n",
    "path = \"sample_image.JPG\" #path to single image\n",
    "PATH = \"training_data.npy\" #path to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA =False # set to true to one once, then back to false unless you want to change something in your"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preparing data.\n",
    "class DogsVSCats():\n",
    "    #IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" or \"jpeg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[\n",
    "                            self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot\n",
    "                        # print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        # print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(PATH, self.training_data)\n",
    "        print('Cats:', dogsvcats.catcount)\n",
    "        print('Dogs:', dogsvcats.dogcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network with dropout\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "#        self.bn1 = nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "#        self.bn2 = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50, 50).view(-1, 1, 50, 50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.AlphaDropout(p=0.3)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "        '''>>> # With Learnable Parameters\n",
    "        >>> m = nn.BatchNorm2d(100)\n",
    "        >>> # Without Learnable Parameters\n",
    "        >>> m = nn.BatchNorm2d(100, affine=False)\n",
    "        >>> input = torch.randn(20, 100, 35, 45)\n",
    "        >>> output = m(input)'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model & parameters\n",
    "net = Net().to(device)\n",
    "\n",
    "#parameters\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a data loader function\n",
    "\n",
    "def load_data(path):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    print(len(data))   \n",
    "    X = torch.Tensor([i[0] for i in data]).view(-1, 50, 50) #images\n",
    "    X = X / 255.0 # scaling the data\n",
    "    print(X.size())\n",
    "    y = torch.Tensor([i[1] for i in data]) #observations / real labels\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24998\n",
      "torch.Size([24998, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "PATH = \"testing_data.npy\"\n",
    "\n",
    "X, y = load_data(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499\n",
      "22499\n",
      "2499\n",
      "10.003201280512204\n",
      "22499\n"
     ]
    }
   ],
   "source": [
    "def create_sets(X,y):\n",
    "    val_size = int(len(X) * VAL_PCT)\n",
    "    print(val_size)\n",
    "\n",
    "    #creating data and train sets.\n",
    "\n",
    "    train_X = X[:-val_size]\n",
    "    train_y = y[:-val_size]\n",
    "\n",
    "    test_X = X[-val_size:]\n",
    "    test_y = y[-val_size:]\n",
    "\n",
    "    print(len(train_X))\n",
    "    print(len(test_X))\n",
    "\n",
    "    print(len(X)/2499)\n",
    "    sampler = SubsetRandomSampler(list(range(int(len(train_X)))))\n",
    "\n",
    "    test_sampler = SubsetRandomSampler(list(range(int(len(test_X)))))\n",
    "\n",
    "    t_dataset = TensorDataset(train_X , train_y)\n",
    "    trainloader = DataLoader(t_dataset , batch_size = BATCH_SIZE, sampler= sampler)\n",
    "\n",
    "    v_dataset = TensorDataset(test_X, test_y)\n",
    "    testloader = DataLoader(v_dataset, batch_size = BATCH_SIZE, sampler= test_sampler)\n",
    "    \n",
    "    return trainloader, testloader, val_size\n",
    "\n",
    "train, test, validsize= create_sets(X,y)\n",
    "\n",
    "n = len(X) - validsize # iteration number\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(net):\n",
    "    with open(\"model_new.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, n, BATCH_SIZE)):   \n",
    "                dt = next(iter(train))\n",
    "                batch_X = dt[0].view(-1, 1, 50, 50)\n",
    "                batch_y = dt[1]\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                acc, loss = fwd_pass(batch_X, batch_y , train_=True)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    val_acc, val_loss = Test(size=100)\n",
    "                    f.write(\n",
    "                        f\"{MODEL_NAME},{round(time.time(), 3)},{round(float(acc), 2)},{round(float(loss), 4)},\"\n",
    "                        f\"{round(float(val_acc), 2)},{round(float(val_loss), 4)},{epoch}\\n\")\n",
    "                    torch.save({\n",
    "                        'dropout cnn model': MODEL_NAME,\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()\n",
    "                    }, PT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(size=32):\n",
    "    test_dt = next(iter(test))\n",
    "    X, y = test_dt[0].view(-1, 1, 50, 50), test_dt[1]\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50).to(device), y.to(device))\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model_new.log\", \"r\").read().split(\"\\n\")\n",
    "\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "\n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "\n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, val_acc, val_loss, epoch = c.split(\",\")\n",
    "\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            val_accs.append(float(val_acc))\n",
    "            val_losses.append(float(val_loss))\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = plt.subplot2grid((2, 1), (0, 0))\n",
    "    ax2 = plt.subplot2grid((2, 1), (1, 0), sharex=ax1)\n",
    "\n",
    "    ax1.plot(times, accuracies, label=\"acc\")\n",
    "    ax1.plot(times, val_accs, label=\"val_acc\")\n",
    "    ax1.legend(loc=2)\n",
    "    ax2.plot(times, losses, label=\"loss\")\n",
    "    ax2.plot(times, val_losses, label=\"val_loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train_=False):\n",
    "    if train_:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True) / len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "\n",
    "    if train_:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-Mon Jul 20 21:04:13 2020\n"
     ]
    }
   ],
   "source": [
    "style.use(\"ggplot\")\n",
    "MODEL_NAME = f\"model-{time.asctime()}\" \n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:50<00:00,  5.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:48<00:00,  6.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:48<00:00,  6.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:49<00:00,  6.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:51<00:00,  5.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:49<00:00,  6.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:53<00:00,  5.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:46<00:00,  6.46it/s]\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 255/300 [00:45<00:07,  5.83it/s]"
     ]
    }
   ],
   "source": [
    "Train(net)\n",
    "create_acc_loss_graph(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading existing model:\n",
    "\n",
    "model = Net().to(device)\n",
    "opt = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in opt.state_dict():\n",
    "    print(var_name, \"\\t\", opt.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_prediction(path)\n",
    "    print(os.path.exists(path))\n",
    "\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE )\n",
    "\n",
    "    #if img == None: # older numpy / py2\n",
    "        # fail !!\n",
    "    #    print(\"fail!1\")\n",
    "\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    x = torch.Tensor([i for i in img]).view(-1, 1, 50, 50)\n",
    "    x = x/255\n",
    "    x = x.to(device)\n",
    "\n",
    "    y= torch.Tensor([0,1]).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    yhat = model(x)\n",
    "    print(yhat)\n",
    "\n",
    "    acc_, loss_ = fwd_pass(x, y)\n",
    "    print(acc_, loss_)\n",
    "    \n",
    "    if acc_ == 1.0:\n",
    "        print(f\"Machine has predicted True! It predicted {yhat} and the input was a image of {y}. \")\n",
    "    else: \n",
    "        print(f\"Machine has predicted False! It predicted {yhat} and the input was a image of {y}. \")\n",
    "    \n",
    "    return\n",
    "\n",
    "single_image_prediction(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"yhat = []\n",
    "for i in range(500):\n",
    "    fname = \"D:/projects/Neural_Networks/coursera_v2/PetImages/dog/\" + str(i)+ \".jpeg\"\n",
    "    #print(fname)\n",
    "    img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    #if img == None: # older numpy / py2\n",
    "    # fail !!\n",
    "    #    print(\"fail!1\")\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    test_x = x.view(-1, 1, 50, 50)\n",
    "    test_x = test_x.to(device)\n",
    "    net.eval()\n",
    "    #with torch.no_grad():\n",
    "    yhat.append(net(test_x))\n",
    "    print(yhat[i])\n",
    "    \n",
    "matches = [torch.argmax(yhat[i]) == torch.argmax(y) for i in range(len(yhat))]\n",
    "acc = matches.count(True) / len(matches)\n",
    "print(acc)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sample = test_X[0:0 + BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "sample = sample.to(device)\n",
    "#with torch.no_grad():\n",
    "output = model(sample)\n",
    "acc_, loss_ = fwd_pass(sample,test_y[0:0 + BATCH_SIZE].to(device) )\n",
    "print(acc_, loss_)\n",
    "print(output, \"=?\", test_y[0:0 + BATCH_SIZE]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"t.npy\", allow_pickle=True)\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([i[0] for i in samples]).view(-1, 1, 50, 50)\n",
    "x = x / 255.0 # scaling the data\n",
    "\n",
    "print(x)\n",
    "obs = torch.Tensor([i[1] for i in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "opt = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load(PT)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "outputs = model(x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_, loss_ = fwd_pass(x.to(device), obs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"D:/projects/Neural_Networks/coursera_v2/PetImages/test/cat/cat.jpg\"\n",
    "    #print(fname)\n",
    "img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    #if img == None: # older numpy / py2\n",
    "    # fail !!\n",
    "    #    print(\"fail!1\")\n",
    "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "x_ = torch.Tensor([i for i in img]).view(-1, 1, 50, 50)\n",
    "x_ = x_ / 255.0\n",
    "print(x_)\n",
    "\n",
    "outout= model(x_.to(device))\n",
    "\n",
    "print(outout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)- val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Machine has predicted True! It is a {outout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit1c7e0d59a08a45f4af234373199ae9c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
